<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blogs | Yang Li&#39;s Website</title>
    <link>https://tianlonglee.github.io/blog/</link>
      <atom:link href="https://tianlonglee.github.io/blog/index.xml" rel="self" type="application/rss+xml" />
    <description>Blogs</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© 2021 Yang Li</copyright><lastBuildDate>Sat, 13 Mar 2021 14:53:35 +0800</lastBuildDate>
    <image>
      <url>https://tianlonglee.github.io/media/icon_hu15d2c9f596ce133d607e52472f13b9a6_10973_512x512_fill_lanczos_center_3.png</url>
      <title>Blogs</title>
      <link>https://tianlonglee.github.io/blog/</link>
    </image>
    
    <item>
      <title>Deep Learning in Spiking Neural Network</title>
      <link>https://tianlonglee.github.io/blog/20210313_deep_learning_in_snn/</link>
      <pubDate>Sat, 13 Mar 2021 14:53:35 +0800</pubDate>
      <guid>https://tianlonglee.github.io/blog/20210313_deep_learning_in_snn/</guid>
      <description>&lt;p&gt;人工神经网络（ANN）主要使用具有连续激活值和一组加权输入的理想化计算单元构建。这些单元由于其生物学灵感而通常被称为“神经元”。这些（非脉冲）神经元使用可微的非线性激活函数。非线性激活函数使得堆叠不止一层的网络具有代表性，并且它们导数的存在使得可以使用基于梯度的优化方法进行训练。随着大型可用带标签的数据集的最新发展、通用GPU计算形式的计算能力以及先进的正则化方法，这些网络已经变得非常深（数十层），并且具有泛化为不可视数据的强大能力，这种网络的性能已经有了巨大的进步。
一个独特的历史里程碑是2012年ILSVRC图像分类挑战中AlexNet的成功。 AlexNet之所以被称为深度神经网络（DNN），是因为它由大约八个连续的端到端学习层组成，总共有6000万个可训练参数。有关DNN的最新综述，可以查看若干文献。 DNN在许多应用中都非常成功，包括图像识别、物体检测、语音识别、，生物医学和生物信息学、时间数据处理以及许多其他应用。人工智能（AI）的这些最新进展为开发不同的工程应用以及理解生物大脑如何工作开辟了新途径。&lt;/p&gt;
&lt;p&gt;













&lt;figure  id=&#34;figure-a-caption&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div &gt;
        &lt;img alt=&#34;A caption&#34; srcset=&#34;
               /blog/20210313_deep_learning_in_snn/ALBUM/001_hu10fa03916b99bf1d4625000a7c9efcf6_347395_667ea988ea773aa4b823e58ddd5b3c6d.png 400w,
               /blog/20210313_deep_learning_in_snn/ALBUM/001_hu10fa03916b99bf1d4625000a7c9efcf6_347395_38ab79bb3d673541f2aed67499f188ff.png 760w,
               /blog/20210313_deep_learning_in_snn/ALBUM/001_hu10fa03916b99bf1d4625000a7c9efcf6_347395_1200x1200_fit_lanczos_3.png 1200w&#34;
               src=&#34;https://tianlonglee.github.io/blog/20210313_deep_learning_in_snn/ALBUM/001_hu10fa03916b99bf1d4625000a7c9efcf6_347395_667ea988ea773aa4b823e58ddd5b3c6d.png&#34;
               width=&#34;50%&#34;
               height=&#34;346&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption data-pre=&#34;Figure&amp;nbsp;&#34; data-post=&#34;:&amp;nbsp;&#34; class=&#34;numbered&#34;&gt;
      A caption
    &lt;/figcaption&gt;&lt;/figure&gt;
尽管DNN在历史上是受大脑启发的，但与大脑相比，它们的结构、神经计算和学习规则存在根本差异。最重要的区别之一是信息在其单元之间传播的方式，正是这一观察催生了脉冲神经网络（SNN）领域的诞生。在大脑中，神经元之间的通信是通过传播动作电位序列（也称为传到下游神经元的脉冲序列）来完成的。这些单独的脉冲在时间上很稀疏，因此每个脉冲都有很高的信息含量，并且近似具有均匀的幅值（100 mV，脉冲宽度约为1ms）。因此SNN中的信息是通过脉冲时序传达的，包括延迟和脉冲速率，也可能通过群。与实际的生理机制相比，SNN几乎普遍使用理想化的脉冲生成机制。














&lt;figure  id=&#34;figure-a-caption&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div &gt;
        &lt;img alt=&#34;A caption&#34; srcset=&#34;
               /blog/20210313_deep_learning_in_snn/ALBUM/002_hu7ac87cfe8b70c0bcc2da1ebf52da38b5_309612_e2de13c109b8f6804e59c23d5d99d0bb.png 400w,
               /blog/20210313_deep_learning_in_snn/ALBUM/002_hu7ac87cfe8b70c0bcc2da1ebf52da38b5_309612_ca1121fe85c283127efbd455521d859d.png 760w,
               /blog/20210313_deep_learning_in_snn/ALBUM/002_hu7ac87cfe8b70c0bcc2da1ebf52da38b5_309612_1200x1200_fit_lanczos_3.png 1200w&#34;
               src=&#34;https://tianlonglee.github.io/blog/20210313_deep_learning_in_snn/ALBUM/002_hu7ac87cfe8b70c0bcc2da1ebf52da38b5_309612_e2de13c109b8f6804e59c23d5d99d0bb.png&#34;
               width=&#34;760&#34;
               height=&#34;601&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      A caption
    &lt;/figcaption&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;占个坑，有时间再好好写。。。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
